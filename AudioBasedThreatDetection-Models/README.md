ğŸ§ Audio-Based Threat Detection System

Application Domain: Smart School Safety and Performance Monitoring

ğŸ“Œ Introduction

The Audio-Based Threat Detection System is a real-time audio intelligence solution designed to enhance school safety. The system continuously analyzes live audio streams to detect potentially dangerous situations using machine learning and signal processing techniques.

It focuses on both non-speech audio threats (such as screaming or glass breaking) and speech-based threats, while strictly preserving user privacy.

ğŸ¯ Project Objectives

ğŸ”Š Detect abnormal non-speech sounds such as screaming, crying, shouting, and glass breaking

ğŸ—£ï¸ Identify threatening speech using speech-to-text and keyword analysis

âš–ï¸ Reduce false positives using adaptive thresholds and calibration

ğŸ”’ Preserve privacy by avoiding audio storage

ğŸ–¥ï¸ Integrate seamlessly with a web-based administrative dashboard

ğŸ§  System Overview

The system operates using a real-time, three-layer architecture:

Frontend (Browser)
Captures microphone audio using the Web Audio API

Backend (Python + Flask)
Processes audio, extracts features, and performs threat detection

Dashboard (Web Interface)
Displays alerts, detection results, and system controls

Audio is analyzed in short segments and discarded immediately after processing.

âš™ï¸ Core Components
ğŸ¤ Audio Capture and Preprocessing

Audio captured via browser microphone

Resampled and normalized to a standard format

Sent to the backend in short time intervals

ğŸ” Non-Speech Threat Detection

Implemented using a 1D CNN + Bidirectional LSTM

Extracts MFCC and spectral features

Classifies audio into predefined categories

Detected classes include:

crying

screaming

shouting

glass breaking

normal ambient sound

ğŸ—£ï¸ Speech-Based Threat Detection

Converts speech to text using a speech recognition engine

Analyzes text using keyword-based threat detection

Supports English and Sinhala

ğŸ›ï¸ Threat Aggregation and Calibration

Combines speech and non-speech results

Uses noise calibration to adapt to environments

Adjusts sensitivity to reduce false positives

ğŸ” Privacy and Ethical Considerations

Privacy is a core design principle of this system:

âŒ No audio recordings are stored

ğŸ§  Audio is processed only in memory

ğŸ—‘ï¸ Raw audio discarded after feature extraction

ğŸ“Š Only minimal metadata is retained

âœ… Microphone access requires user consent

ğŸ§© Implementation Summary

Backend: Python, Flask, PyTorch

Audio Processing: MFCC and spectral analysis

Frontend Communication: REST APIs

Model Inference: Real-time deep learning

The system is optimized for low latency and reliable detection.

ğŸ› ï¸ Setup Overview

Basic backend setup steps:

Create and activate a virtual environment

Install dependencies using requirements.txt

Run the Flask server using app.py

The backend server runs locally at:
http://127.0.0.1:5002

ğŸŒ API Capabilities

The backend exposes endpoints for:

âœ… Health checks

ğŸ§ Audio analysis

ğŸšï¸ Sensitivity adjustment

ğŸ“¡ Noise calibration

ğŸ”„ Session management

These endpoints allow seamless interaction with the dashboard.

ğŸ“ˆ System Performance

â±ï¸ Average latency: under 3 seconds

ğŸµ Audio chunk duration: 4 seconds

ğŸ“¡ Sample rate: 16 kHz

ğŸ¯ Reduced false positives via calibration

ğŸ“ Academic Context

This project was developed as part of an academic research study focusing on:

Real-time audio intelligence

Machine learning-based threat detection

Privacy-aware system design

All components were implemented, tested, and evaluated through practical experimentation.

âš ï¸ Usage Note

This system is intended for academic and research purposes only. Any real-world deployment must comply with legal, ethical, and institutional regulations.